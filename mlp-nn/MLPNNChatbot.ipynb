{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPNNChatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Implementacija jednostavnog chatbota koristeći MLP NN**\n",
        "\n",
        "Ovaj notebook predstavlja osnovni set koraka za implementaciju jednostavnog chatbota na bazi dubokog i/ili mašinskog učenja koristeći Multi-level perceprton neuronsku mrežu (Sequential model)."
      ],
      "metadata": {
        "id": "M45tPtETT2BX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Osnovni importi"
      ],
      "metadata": {
        "id": "6uIT6dTJVwwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvag31mcUlz1",
        "outputId": "70992b16-f8c1-48a6-dc28-96b46d43b1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKr1I8wWST5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3645a6ce-f45a-4f6e-a294-a53446a4ab8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Učitavanje podataka"
      ],
      "metadata": {
        "id": "U1-n18fpVyW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "f = open('/content/drive/My Drive/BasicNNChatbot/intents.json',)\n",
        "\n",
        "data = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0_GseFZVCp0",
        "outputId": "5beaee89-3868-4c6e-a9b3-911a2cf2d1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretprocesiranje podataka"
      ],
      "metadata": {
        "id": "HFntEvBbVsI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing lemmatizer to get stem of words\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()# Each list to create\n",
        "words = []\n",
        "classes = []\n",
        "doc_X = []\n",
        "doc_y = []# Loop through all the intents\n",
        "\n",
        "\n",
        "# tokenize each pattern and append tokens to words, the patterns and\n",
        "# the associated tag to their associated listfor intent in data[\"intents\"]:\n",
        "for intent in data[\"intents\"]:\n",
        "  for pattern in intent[\"patterns\"]:\n",
        "      tokens = nltk.word_tokenize(pattern)\n",
        "      words.extend(tokens)\n",
        "      doc_X.append(pattern)\n",
        "      doc_y.append(intent[\"tag\"])\n",
        "\n",
        "  # add the tag to the classes if it's not there already \n",
        "  if intent[\"tag\"] not in classes:\n",
        "      classes.append(intent[\"tag\"])# lemmatize all the words in the vocab and convert them to lowercase\n",
        "\n",
        "\n",
        "# if the words don't appear in punctuation\n",
        "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]# sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplicates occur\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "id": "l5nLHrs1Vrhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ispis rezultata pretprocesiranja"
      ],
      "metadata": {
        "id": "gadAglEnWSVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)\n",
        "print('------------------------------------------------------------------------------------')\n",
        "print(classes)\n",
        "print('------------------------------------------------------------------------------------')\n",
        "print(doc_X)\n",
        "print('------------------------------------------------------------------------------------')\n",
        "print(doc_y)\n",
        "print('------------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LbQq9wHWR8K",
        "outputId": "14f369aa-3741-40c0-bbfc-edf9e3bf7d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'s\", 'adios', 'are', 'birthday', 'born', 'bye', 'called', 'cao', 'cya', 'do', 'doing', 'for', 'g2g', 'hang', 'hello', 'hi', 'how', 'is', 'name', 'old', 'out', 'plan', 'see', 'some', 'there', 'this', 'time', 'to', 'up', 'want', 'week', 'weekend', 'were', 'what', 'whats', 'when', 'who', 'ya', 'you', 'your']\n",
            "------------------------------------------------------------------------------------\n",
            "['age', 'date', 'goodbye', 'greeting', 'name']\n",
            "------------------------------------------------------------------------------------\n",
            "['Hello', 'How are you?', 'Hi there', 'Hi', 'Whats up', 'Cao', 'How old are you?', 'When is your birthday?', 'When were you born?', 'what are you doing this weekend?', 'do you want to hang out some time?', 'what are your plans for this week', \"what's your name?\", 'what are you called?', 'who are you?', 'bye', 'g2g', 'see ya', 'adios', 'cya']\n",
            "------------------------------------------------------------------------------------\n",
            "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'age', 'age', 'age', 'date', 'date', 'date', 'name', 'name', 'name', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye']\n",
            "------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Priprema trening podataka"
      ],
      "metadata": {
        "id": "E_z4WrHMWp5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list for training data\n",
        "training = []\n",
        "out_empty = [0] * len(classes)# creating the bag of words model\n",
        "for idx, doc in enumerate(doc_X):\n",
        "    bow = []\n",
        "    text = lemmatizer.lemmatize(doc.lower())\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)    # mark the index of class that the current pattern is associated\n",
        "    # to\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_y[idx])] = 1    # add the one hot encoded BoW and associated classes to training \n",
        "    training.append([bow, output_row])# shuffle the data and convert it to an array\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)# split the features and target labels\n",
        "train_X = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))"
      ],
      "metadata": {
        "id": "DscoAtL_Wprx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "A8NV5Vf5WuGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining some parameters\n",
        "input_shape = (len(train_X[0]),)\n",
        "output_shape = len(train_y[0])\n",
        "epochs = 200\n",
        "\n",
        "# the deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "history = model.fit(x=train_X, y=train_y, epochs=200, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C54mwSf9WwSI",
        "outputId": "a8111322-6794-4f1b-df60-178693da4823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 128)               5248      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,829\n",
            "Trainable params: 13,829\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 531ms/step - loss: 1.6160 - accuracy: 0.2500\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6126 - accuracy: 0.3000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4448 - accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3214 - accuracy: 0.6500\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2897 - accuracy: 0.6500\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1406 - accuracy: 0.8000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9282 - accuracy: 0.9000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7668 - accuracy: 0.8000\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7743 - accuracy: 0.8500\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6989 - accuracy: 0.9000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5029 - accuracy: 0.9000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4037 - accuracy: 0.9500\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4512 - accuracy: 0.9000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3491 - accuracy: 0.9000\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2559 - accuracy: 0.9500\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2648 - accuracy: 0.9500\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9500\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1664 - accuracy: 0.9500\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0999 - accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1123 - accuracy: 0.9500\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9500\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0742 - accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1176 - accuracy: 0.9500\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9500\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9500\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2845 - accuracy: 0.9000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2952e-04 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3663e-04 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2846e-04 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1338e-04 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.2458e-04 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.8215e-04 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.4939e-04 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.7278e-04 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.7789e-04 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9616e-04 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0428e-04 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4528e-04 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2640e-04 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8132e-04 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6566e-04 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4245e-04 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2187e-04 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8576e-04 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4706e-04 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4310e-04 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0980e-04 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1774e-04 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1536e-04 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2027e-04 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8272e-04 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4877e-04 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8421e-04 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1659e-04 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8174e-04 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4484e-04 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3087e-04 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6060e-04 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3739e-05 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1119e-04 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8940e-05 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8258e-04 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9955e-04 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7668e-04 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6859e-04 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5183e-04 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4212e-05 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2595e-05 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8027e-04 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8191e-04 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6558e-04 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0163e-04 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4436e-04 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0565e-04 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6453e-04 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.8616e-05 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4187e-04 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3587e-04 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.0614e-05 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.7456e-04 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6948e-04 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2250e-04 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1106e-04 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0970e-04 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9116e-04 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2299e-05 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4382e-04 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8441e-04 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.1326e-04 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8530e-05 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0807e-04 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8727e-04 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5515e-05 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4043e-04 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2028e-04 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6665e-05 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6510e-05 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3624e-04 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6098e-05 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8667e-05 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1099e-04 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3816e-05 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5345e-04 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.3100e-05 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5438e-05 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7040e-04 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1581e-05 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2257e-04 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2428e-04 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1520e-04 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.4348e-05 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8309e-04 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1092e-04 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6081e-05 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4245e-05 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7085e-04 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6080e-04 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2078e-04 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3652e-04 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1499e-04 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.5102e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_p0B5qwdXLv1",
        "outputId": "dc73f1c7-21ff-4281-85bb-3ad658b9886c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nakon formiranja modela za chatbot, prelazimo na kreiranje pomoćnih funkcija za osnovnu implementaciju chatbota:"
      ],
      "metadata": {
        "id": "p8yyrCn2X-3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text): \n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "def bag_of_words(text, vocab): \n",
        "  tokens = clean_text(text)\n",
        "  bow = [0] * len(vocab)\n",
        "  for w in tokens: \n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w: \n",
        "        bow[idx] = 1\n",
        "  return np.array(bow)\n",
        "\n",
        "def pred_class(text, vocab, labels): \n",
        "  bow = bag_of_words(text, vocab)\n",
        "  result = model.predict(np.array([bow]))[0]\n",
        "  thresh = 0.2\n",
        "  y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "\n",
        "  y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in y_pred:\n",
        "    return_list.append(labels[r[0]])\n",
        "  return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json): \n",
        "  tag = intents_list[0]\n",
        "  list_of_intents = intents_json[\"intents\"]\n",
        "  for i in list_of_intents: \n",
        "    if i[\"tag\"] == tag:\n",
        "      result = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  return result"
      ],
      "metadata": {
        "id": "7sf3G7xgYKI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Za pokretanje chatbota, koristit ćemo beskonačnu petlju:"
      ],
      "metadata": {
        "id": "YSZOdzYyYOoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running the chatbot\n",
        "while True:\n",
        "    print(\"YOU: \")\n",
        "    message = input(\"\")\n",
        "    intents = pred_class(message, words, classes)\n",
        "    result = get_response(intents, data)\n",
        "    print(\"LAKI: \")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "ONlaRpPgYTQq",
        "outputId": "4f6ba8fb-30f9-487c-e768-11e9264bec0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOU: \n",
            "Cao\n",
            "LAKI: \n",
            "Pa gdje si ti\n",
            "YOU: \n",
            "what are you doing this weekend?\n",
            "LAKI: \n",
            "Ne mogu, radim DAP projekat\n",
            "YOU: \n",
            "bye\n",
            "LAKI: \n",
            "See you later\n",
            "YOU: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \"\"\"\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c2aa3bfdbc76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"YOU: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}