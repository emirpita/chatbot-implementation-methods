{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUqyHh4ejptA"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuXyLHVxsQo9",
        "outputId": "8abe5a8f-abfb-4e90-a9e7-9ac4001bed54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#NLTK packages download\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet') \n",
        "nltk.download('nps_chat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3ZXqB3FDsd0k"
      },
      "outputs": [],
      "source": [
        "#Global Constants\n",
        "FILENAME           = \"faq_dap_projekat\"\n",
        "GREETING_INPUTS    = (\"hello\", \"hi\", \"hey\")\n",
        "GREETING_RESPONSES = [\"hello\", \"hi\", \"hey\", \"hi there\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "HpD_ouDRRpkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca03f81-430f-4248-f2bd-49ded152a8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q: what are your shipping options?++++\n",
            "\n",
            "we ship with dhl and ups, which often complete delivery via usps.++++\n",
            "\n",
            "q: do you offer expedited shipping?++++\n",
            "\n",
            "we don’t offer expedited shipping at this time, but if you want to peer into the crystal ball to see when your order will arrive, email us at hello@magicspoon.com.++++\n",
            "\n",
            "q: how long will it take for my order to arrive?++++\n",
            "\n",
            "once you place your order, it’ll process within 1 business day.from there we’ll ship it out and send you your tracking number once it’s out the door.give your tracking number 24 hours to update once you receive it, and then wait patiently for your cereal game to completely change.++++\n",
            "\n",
            "q: can i edit or cancel my order once it’s been placed?++++\n",
            "\n",
            "hurry!there’s only a short window of time for us to edit or cancel your order.e-mail hello@magicspoon.com and we’ll do our best to work some magic for you.++++\n",
            "\n",
            "q: how do i track my package?++++\n",
            "\n",
            "you’ll receive a shipping confirmation with your tracking number as soon as your order ships out.give that tracking number 24 hours to update once you receive it, and then you can follow your order on it’s journey to you.++++\n",
            "\n",
            "q: do you have any samples?++++\n",
            "\n",
            "we aren’t able to send out any samples at the moment!however, feel free to order your first 4 pack case and give us a try!if you don’t love it, we’ll refund your first case in full.++++\n",
            "\n",
            "q: what kind of sorcery is this?where did all the carbs and sugar go?++++\n",
            "\n",
            "we spent over a year working through hundreds of formulations in a quest to recreate our favorite childhood cereals without the junk.we eventually figured out a way to include all of the good stuff you want—like protein and healthy fats—without any of the bad stuff you don’t.++++\n",
            "\n",
            "q: why is this more expensive than “regular” cereal?++++\n",
            "\n",
            "even though magic spoon looks and tastes like most cereals you’ll find at the grocery store, nutritionally, it’s lightyears ahead.think of magic spoon as more of a high-end protein bar or keto smoothie.and at $1.95 per bowl, it’s far cheaper than those other healthy breakfast options (not to mention your morning coffee)!making cereal with high nutritional value means working with more expensive ingredients than just sugar, corn, and wheat, but it’s all part of our commitment to bring you the best!++++\n",
            "\n",
            "q: do kids eat/like magic spoon?++++\n",
            "\n",
            "absolutely!and since it tastes just like their favorite “unhealthy” cereal, they’ll love eating this instead of other “healthy” cereals.++++\n",
            "\n",
            "q: what are net carbs?++++\n",
            "\n",
            "not all carbs are created equal.fiber and (most) natural sweeteners don’t affect your blood sugar, so they’re stripped out to get “net carbs,” which you can think of as the active carbs that affect your body.in our case, net carbs = total carbs - allulose - fiber.++++\n",
            "\n",
            "q: how big is a case of this cereal?++++\n",
            "\n",
            "one case is 4 individual boxes—each with 5 servings of delicious cereal.of course, if you’re anything like us and enjoy cereal for breakfast, snacks, and if we’re being honest, occasionally for dinner, then a one month supply might magically disappear in a couple of weeks!++++\n",
            "\n",
            "q: what milk should i eat this cereal with?++++\n",
            "\n",
            "magic spoon is delicious with everything from whole milk to oat milk.our favorite is almond milk but you should choose your own adventure.if you want to get really creative, try it as a topping for yogurt or even healthy ice cream.++++\n",
            "\n",
            "q: what does this cereal taste like?++++\n",
            "\n",
            "it tastes just like you remember, only better.++++\n",
            "\n",
            "q: is this cereal kosher?++++\n",
            "\n",
            "yes.magic spoon is certified kosher dairy.++++\n",
            "\n",
            "q: where does the fat content come from?++++\n",
            "\n",
            "the fat you see on our nutrition label is “healthy” fat, from a blend of high-oleic sunflower oil and avocado oil.++++\n",
            "\n",
            "q: how long does this cereal stay fresh/what is the shelf life?++++\n",
            "\n",
            "our cereal has a 9 month shelf-life.++++\n",
            "\n",
            "q: how does this compare to other \"healthy\" cereals?++++\n",
            "\n",
            "even “healthy” breakfast cereals like granola are typically loaded with added sugars, with many of the leading brands containing as much sugar as candy.you can see how we compare to a variety of cereals on our \"us vs. them\" page.++++\n",
            "\n",
            "q: what is allulose?++++\n",
            "\n",
            "allulose is a “rare” sugar found in things like figs and maple syrup.it tastes just like “regular” sugar, but has almost zero glycemic impact and almost zero calories (less than 0.4 cal/g).++++\n",
            "\n",
            "q: is magic spoon cereal vegan?++++\n",
            "\n",
            "right now, our cereal isn't vegan and we don't have any plans for a vegan cereal in the immediate future, but we're definitely keeping it in mind as we continue to expand our product line!it's always helpful to hear from our prospective customers as to what they're looking for, so send us an email at hello@magicspoon.com to let us know what you’d like to see from us!++++\n",
            "\n",
            "q: is magic spoon cereal dairy-free?++++\n",
            "\n",
            "our protein concentrates are lactose-free!++++\n",
            "\n",
            "q: is magic spoon cereal gluten-free?++++\n",
            "\n",
            "our cereal is certified gluten-free, but it is made in a shared facility.we test product in and product out, and can guarantee that we comply with the gluten-free certification organization's requirement to contain no more than 10 parts per million gluten.++++\n",
            "\n",
            "q: is magic spoon cereal high protein?++++\n",
            "\n",
            "yes!just one serving of magic spoon cereal has 13-14g grams of high quality protein.that is 10 times more than other popular cereal brands!in addition, magic spoon is also keto-friendly, low carb, gluten-free, and grain-free!++++\n",
            "\n",
            "q: what flavors contain nuts?++++\n",
            "\n",
            "all our cereal, with the exception of peanut butter, is manufactured in a facility that handles other varieties of nuts.we do not use any nuts in the formulation of our cereals [except for peanut butter] but the facility we manufacture in is not nut-free.if you specifically have a peanut allergy, we can guarantee that no other flavors are exposed to peanuts, as we manufacture our peanut butter flavor in a completely separate facility.++++\n",
            "\n",
            "q: is there any minimum commitment for a subscription?++++\n",
            "\n",
            "no, you can cancel your subscription at anytime.++++\n",
            "\n",
            "q: how do i update subscription billing information?++++\n",
            "\n",
            "in the billing information tab you'll find the current method of payment along with the current billing address.however, this is not the same as the shipping address.you would edit the address in this section if something has changed for the card holder's place of residence or the email address on file.++++\n",
            "\n",
            "q: how do i skip a subscription delivery?++++\n",
            "\n",
            "once logged in, click on delivery schedule on the left to see all upcoming deliveries for your subscriptions.to skip a delivery you can click skip to the right of each one.++++\n",
            "\n",
            "q: how do i update my subscription shipping address?++++\n",
            "\n",
            "once logged in, click on subscriptions and click edit to the right of the address.this only affects the shipping/delivery address, this does not update billing information related to the method of payment.++++\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Global Variables\n",
        "lem = nltk.stem.WordNetLemmatizer()\n",
        "remove_punctuation = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "question_file = open(FILENAME,'r',errors = 'ignore')\n",
        "quesstion_file_text = question_file.read().lower()\n",
        "sent_tokens = nltk.sent_tokenize(quesstion_file_text)# converts to list of sentences \n",
        "word_tokens = nltk.word_tokenize(quesstion_file_text)# converts to list of words\n",
        "for i in sent_tokens:\n",
        "  print(i + '++++\\n')\n",
        "question_answers_dictionary = {} #The Dictionary to store questions and corresponding answers\n",
        "question_list = [] #List of all questions\n",
        "sentence_counter = 0  #Sentence counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dKNqn6U0sgys"
      },
      "outputs": [],
      "source": [
        "def fetch_features(chat):\n",
        "    features = {}\n",
        "    for word in nltk.word_tokenize(chat):\n",
        "        features['contains({})'.format(word.lower())] = True\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sAMiZfIlsnTo"
      },
      "outputs": [],
      "source": [
        "def lemmatise(tokens):\n",
        "    return [lem.lemmatize(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ZNn7EgxLsqO3"
      },
      "outputs": [],
      "source": [
        "def tokenise(text):\n",
        "    return lemmatise(nltk.word_tokenize(text.lower().translate(remove_punctuation)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "SWbT_i-2ssqM"
      },
      "outputs": [],
      "source": [
        "def greet(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-QyjQTJOsvnZ"
      },
      "outputs": [],
      "source": [
        "def match(user_response):\n",
        "    response = ''\n",
        "    question_list.append(user_response)\n",
        "    tfidf = TfidfVectorizer(tokenizer=tokenise, stop_words='english').fit_transform(question_list)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx = vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf == 0):\n",
        "        response = response + \"Sorry! I don't know the answer to this. Would you like to try again? Type By to exit\"\n",
        "        return response\n",
        "    else:\n",
        "        resp_ids = question_answers_dictionary[idx]\n",
        "        resp_str = ''\n",
        "        s_id = resp_ids[0]\n",
        "        end = resp_ids[1]\n",
        "        while s_id < end :\n",
        "            resp_str = resp_str + \" \" + sent_tokens[s_id]\n",
        "            s_id += 1\n",
        "        response = response + resp_str\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNTTSOgLsz4T",
        "outputId": "0c16698b-7a3e-4445-ed07-efbe9b4c9271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (100 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -2.70805        0.048\n",
            "             2          -1.24031        0.864\n",
            "             3          -0.90963        0.895\n",
            "             4          -0.73810        0.909\n",
            "             5          -0.62531        0.920\n",
            "             6          -0.54248        0.929\n",
            "             7          -0.47821        0.935\n",
            "             8          -0.42715        0.940\n",
            "             9          -0.38627        0.944\n",
            "            10          -0.35340        0.948\n",
            "            11          -0.32676        0.952\n",
            "            12          -0.30487        0.954\n",
            "            13          -0.28657        0.956\n",
            "            14          -0.27101        0.958\n",
            "            15          -0.25757        0.960\n",
            "            16          -0.24581        0.962\n",
            "            17          -0.23541        0.964\n",
            "            18          -0.22612        0.965\n",
            "            19          -0.21776        0.967\n",
            "            20          -0.21019        0.967\n",
            "            21          -0.20329        0.968\n",
            "            22          -0.19696        0.968\n",
            "            23          -0.19114        0.969\n",
            "            24          -0.18576        0.970\n",
            "            25          -0.18077        0.971\n",
            "            26          -0.17612        0.971\n",
            "            27          -0.17178        0.971\n",
            "            28          -0.16771        0.972\n",
            "            29          -0.16390        0.973\n",
            "            30          -0.16030        0.973\n",
            "            31          -0.15691        0.973\n",
            "            32          -0.15371        0.974\n",
            "            33          -0.15068        0.974\n",
            "            34          -0.14780        0.974\n",
            "            35          -0.14507        0.975\n",
            "            36          -0.14247        0.975\n",
            "            37          -0.13999        0.975\n",
            "            38          -0.13762        0.975\n",
            "            39          -0.13536        0.976\n",
            "            40          -0.13319        0.976\n",
            "            41          -0.13112        0.976\n",
            "            42          -0.12913        0.977\n",
            "            43          -0.12723        0.977\n",
            "            44          -0.12539        0.977\n",
            "            45          -0.12363        0.977\n",
            "            46          -0.12193        0.977\n",
            "            47          -0.12029        0.978\n",
            "            48          -0.11872        0.978\n",
            "            49          -0.11720        0.978\n",
            "            50          -0.11573        0.978\n",
            "            51          -0.11430        0.978\n",
            "            52          -0.11293        0.979\n",
            "            53          -0.11160        0.979\n",
            "            54          -0.11031        0.979\n",
            "            55          -0.10906        0.979\n",
            "            56          -0.10785        0.979\n",
            "            57          -0.10668        0.979\n",
            "            58          -0.10554        0.979\n",
            "            59          -0.10444        0.980\n",
            "            60          -0.10336        0.980\n",
            "            61          -0.10232        0.980\n",
            "            62          -0.10130        0.980\n",
            "            63          -0.10031        0.980\n",
            "            64          -0.09935        0.980\n",
            "            65          -0.09841        0.980\n",
            "            66          -0.09750        0.980\n",
            "            67          -0.09661        0.980\n",
            "            68          -0.09574        0.981\n",
            "            69          -0.09489        0.981\n",
            "            70          -0.09407        0.981\n",
            "            71          -0.09326        0.981\n",
            "            72          -0.09247        0.981\n",
            "            73          -0.09170        0.981\n",
            "            74          -0.09095        0.981\n",
            "            75          -0.09022        0.981\n",
            "            76          -0.08950        0.981\n",
            "            77          -0.08880        0.981\n",
            "            78          -0.08811        0.981\n",
            "            79          -0.08744        0.981\n",
            "            80          -0.08678        0.981\n",
            "            81          -0.08614        0.981\n",
            "            82          -0.08550        0.982\n",
            "            83          -0.08489        0.982\n",
            "            84          -0.08428        0.982\n",
            "            85          -0.08369        0.982\n",
            "            86          -0.08310        0.982\n",
            "            87          -0.08253        0.982\n",
            "            88          -0.08197        0.982\n",
            "            89          -0.08142        0.982\n",
            "            90          -0.08088        0.982\n",
            "            91          -0.08035        0.982\n",
            "            92          -0.07983        0.982\n",
            "            93          -0.07932        0.983\n",
            "            94          -0.07882        0.983\n",
            "            95          -0.07833        0.983\n",
            "            96          -0.07785        0.983\n",
            "            97          -0.07737        0.983\n",
            "            98          -0.07691        0.983\n",
            "            99          -0.07645        0.983\n",
            "         Final          -0.07600        0.983\n",
            "0.715\n"
          ]
        }
      ],
      "source": [
        "#Training the classifier\n",
        "chats = nltk.corpus.nps_chat.xml_posts()[:10000]\n",
        "featuresets = [(fetch_features(chat.text), chat.get('class')) for chat in chats]\n",
        "size = int(len(featuresets) * 0.3)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.MaxentClassifier.train(train_set) \n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Am6Qfe2FvyQ5"
      },
      "outputs": [],
      "source": [
        "#Extract questions and answers\n",
        "#Answer is all the content between 2 questions [assumption]\n",
        "while sentence_counter < len(sent_tokens):\n",
        "    result = classifier.classify(fetch_features(sent_tokens[sentence_counter]))\n",
        "    if(\"question\" in result.lower()):\n",
        "        next_question_id = sentence_counter + 1\n",
        "        next_question = classifier.classify(fetch_features(sent_tokens[next_question_id]))\n",
        "        while(not(\"question\" in next_question.lower()) and next_question_id < len(sent_tokens) - 1):\n",
        "            next_question_id += 1\n",
        "            next_question = classifier.classify(fetch_features(sent_tokens[next_question_id]))\n",
        "        question_list.append(sent_tokens[sentence_counter])\n",
        "        end = next_question_id\n",
        "        if(next_question_id - sentence_counter > 5):\n",
        "            end = sentence_counter + 5\n",
        "        question_answers_dictionary.update({len(question_list) - 1:[sentence_counter + 1, end]})\n",
        "        sentence_counter = next_question_id\n",
        "    else:\n",
        "        sentence_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLisi1rKv2dt",
        "outputId": "a8ff0f7e-98f2-407f-927a-6cf021ed42b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[34mBOT:\n",
            "I am Bot, Chat Bot. I have all the answers If you want to exit, type By\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "hi\n",
            "\u001b[1m\u001b[34m\n",
            "BOT:\u001b[0m\n",
            "hello\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "how long stay fresh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[34m\n",
            "BOT:\u001b[0m\n",
            "\u001b[34mOur cereal has a 9 month shelf-life.\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "Is Magic Spoon cereal vegan?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[34m\n",
            "BOT:\u001b[0m\n",
            "\u001b[34mRight now, our cereal isn't vegan and we don't have any plans for a vegan cereal in the immediate future, but we're definitely keeping it in mind as we continue to expand our product line!it's always helpful to hear from our prospective customers as to what they're looking for, so send us an email at hello@magicspoon.com to let us know what you’d like to see from us!\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "is it vegan?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[34m\n",
            "BOT:\u001b[0m\n",
            "\u001b[34mRight now, our cereal isn't vegan and we don't have any plans for a vegan cereal in the immediate future, but we're definitely keeping it in mind as we continue to expand our product line!it's always helpful to hear from our prospective customers as to what they're looking for, so send us an email at hello@magicspoon.com to let us know what you’d like to see from us!\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "Where does the fat content come from?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[34m\n",
            "BOT:\u001b[0m\n",
            "\u001b[34mThe fat you see on our nutrition label is “healthy” fat, from a blend of high-oleic sunflower oil and avocado oil.\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "Do kids eat/like Magic Spoon?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[34m\n",
            "BOT:\u001b[0m\n",
            "\u001b[34mAbsolutely!and since it tastes just like their favorite “unhealthy” cereal, they’ll love eating this instead of other “healthy” cereals.\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "YOU:\u001b[0m\n",
            "by\n",
            "\u001b[1m\u001b[34m\n",
            "BOT: Bye!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Response Fetching\n",
        "flag=True\n",
        "print(colored(\"BOT:\\nI am Bot, Chat Bot. I have all the answers If you want to exit, type By\",'blue',attrs=['bold']))\n",
        "while(flag==True):\n",
        "    print(colored(\"\\nYOU:\",'red',attrs=['bold']))\n",
        "    u_input = input()\n",
        "    u_input = u_input.lower()\n",
        "    if(u_input != 'by'):\n",
        "        print(colored(\"\\nBOT:\",'blue',attrs=['bold']))\n",
        "        if(greet(u_input)!=None):\n",
        "            print(greet(u_input))\n",
        "        else:\n",
        "            print(colored(match(u_input).strip().capitalize(),'blue'))\n",
        "            question_list.remove(u_input)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(colored(\"\\nBOT: Bye!\",'blue', attrs=['bold']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DAP_projekat_Maxent_Classifier .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}